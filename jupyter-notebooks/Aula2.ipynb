{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('fruit_data_with_colors_miss.txt',\n",
    "                    na_values=['.','?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>178.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>172.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>166.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>172.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>164.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>152.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>156.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>156.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>162.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>156.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>140.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>170.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>342.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>356.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>362.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>204.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>158.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>210.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>164.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>142.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>150.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>158.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>180.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>194.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>186.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>216.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>196.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>174.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>132.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>152.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>lemon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>118.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit_label fruit_name     fruit_subtype   mass  width  height  \\\n",
       "0             1      apple      granny_smith  192.0    8.4     7.3   \n",
       "1             1      apple      granny_smith  180.0    8.0     6.8   \n",
       "2             1      apple      granny_smith  176.0    7.4     7.2   \n",
       "3             2   mandarin          mandarin    NaN    6.2     4.7   \n",
       "4             2   mandarin          mandarin   84.0    6.0     4.6   \n",
       "5             2   mandarin          mandarin   80.0    5.8     4.3   \n",
       "6             2   mandarin          mandarin   80.0    5.9     4.3   \n",
       "7             2   mandarin               NaN   76.0    5.8     4.0   \n",
       "8             1      apple          braeburn  178.0    7.1     NaN   \n",
       "9             1      apple          braeburn  172.0    7.4     7.0   \n",
       "10            1      apple          braeburn  166.0    6.9     7.3   \n",
       "11            1      apple          braeburn  172.0    7.1     7.6   \n",
       "12            1      apple          braeburn  154.0    7.0     7.1   \n",
       "13            1      apple  golden_delicious  164.0    7.3     7.7   \n",
       "14            1      apple  golden_delicious  152.0    7.6     7.3   \n",
       "15            1      apple  golden_delicious  156.0    7.7     7.1   \n",
       "16            1      apple  golden_delicious  156.0    7.6     7.5   \n",
       "17            1      apple  golden_delicious  168.0    7.5     7.6   \n",
       "18            1      apple       cripps_pink  162.0    7.5     7.1   \n",
       "19            1      apple       cripps_pink  162.0    7.4     7.2   \n",
       "20            1      apple       cripps_pink  160.0    7.5     7.5   \n",
       "21            1      apple       cripps_pink  156.0    7.4     7.4   \n",
       "22            1      apple       cripps_pink  140.0    7.3     7.1   \n",
       "23            1      apple       cripps_pink  170.0    7.6     7.9   \n",
       "24            3     orange     spanish_jumbo  342.0    9.0     9.4   \n",
       "25            3     orange     spanish_jumbo  356.0    9.2     9.2   \n",
       "26            3     orange     spanish_jumbo  362.0    9.6     9.2   \n",
       "27            3     orange  selected_seconds  204.0    7.5     9.2   \n",
       "28            3     orange  selected_seconds  140.0    6.7     7.1   \n",
       "29            3     orange  selected_seconds  160.0    7.0     7.4   \n",
       "30            3     orange  selected_seconds  158.0    7.1     7.5   \n",
       "31            3     orange  selected_seconds  210.0    7.8     8.0   \n",
       "32            3     orange  selected_seconds  164.0    7.2     7.0   \n",
       "33            3     orange      turkey_navel  190.0    7.5     8.1   \n",
       "34            3     orange      turkey_navel  142.0    7.6     7.8   \n",
       "35            3     orange      turkey_navel  150.0    7.1     7.9   \n",
       "36            3     orange      turkey_navel  160.0    7.1     7.6   \n",
       "37            3     orange      turkey_navel  154.0    7.3     7.3   \n",
       "38            3     orange      turkey_navel  158.0    7.2     7.8   \n",
       "39            3     orange      turkey_navel  144.0    6.8     7.4   \n",
       "40            3     orange      turkey_navel  154.0    7.1     7.5   \n",
       "41            3     orange      turkey_navel  180.0    7.6     8.2   \n",
       "42            3     orange      turkey_navel  154.0    7.2     7.2   \n",
       "43            4      lemon    spanish_belsan  194.0    7.2    10.3   \n",
       "44            4      lemon    spanish_belsan  200.0    7.3    10.5   \n",
       "45            4      lemon    spanish_belsan  186.0    7.2     9.2   \n",
       "46            4      lemon    spanish_belsan  216.0    7.3    10.2   \n",
       "47            4      lemon    spanish_belsan  196.0    7.3     9.7   \n",
       "48            4      lemon    spanish_belsan  174.0    7.3    10.1   \n",
       "49            4      lemon           unknown  132.0    5.8     8.7   \n",
       "50            4      lemon           unknown  130.0    6.0     8.2   \n",
       "51            4      lemon           unknown  116.0    6.0     7.5   \n",
       "52            4      lemon           unknown  118.0    5.9     8.0   \n",
       "53            4      lemon           unknown  120.0    6.0     8.4   \n",
       "54            4      lemon           unknown  116.0    6.1     8.5   \n",
       "55            4      lemon           unknown  116.0    6.3     7.7   \n",
       "56            4      lemon           unknown  116.0    5.9     8.1   \n",
       "57            4      lemon           unknown  152.0    6.5     8.5   \n",
       "58            4      lemon           unknown  118.0    6.1     8.1   \n",
       "\n",
       "    color_score  \n",
       "0          0.55  \n",
       "1          0.59  \n",
       "2          0.60  \n",
       "3          0.80  \n",
       "4          0.79  \n",
       "5          0.77  \n",
       "6          0.81  \n",
       "7          0.81  \n",
       "8          0.92  \n",
       "9          0.89  \n",
       "10         0.93  \n",
       "11         0.92  \n",
       "12         0.88  \n",
       "13         0.70  \n",
       "14         0.69  \n",
       "15         0.69  \n",
       "16         0.67  \n",
       "17         0.73  \n",
       "18         0.83  \n",
       "19         0.85  \n",
       "20         0.86  \n",
       "21         0.84  \n",
       "22         0.87  \n",
       "23         0.88  \n",
       "24         0.75  \n",
       "25         0.75  \n",
       "26         0.74  \n",
       "27         0.77  \n",
       "28         0.72  \n",
       "29         0.81  \n",
       "30         0.79  \n",
       "31         0.82  \n",
       "32         0.80  \n",
       "33         0.74  \n",
       "34         0.75  \n",
       "35         0.75  \n",
       "36         0.76  \n",
       "37         0.79  \n",
       "38         0.77  \n",
       "39         0.75  \n",
       "40         0.78  \n",
       "41         0.79  \n",
       "42         0.82  \n",
       "43         0.70  \n",
       "44         0.72  \n",
       "45         0.72  \n",
       "46         0.71  \n",
       "47         0.72  \n",
       "48         0.72  \n",
       "49         0.73  \n",
       "50         0.71  \n",
       "51         0.72  \n",
       "52         0.72  \n",
       "53         0.74  \n",
       "54         0.71  \n",
       "55         0.72  \n",
       "56         0.73  \n",
       "57         0.72  \n",
       "58         0.70  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>color_score</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.448276</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.691379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>166.000000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>356.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>204.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>186.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>216.000000</td>\n",
       "      <td>0.71</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>196.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mass  color_score  width     height\n",
       "0   192.000000         0.55    8.4   7.300000\n",
       "1   180.000000         0.59    8.0   6.800000\n",
       "2   176.000000         0.60    7.4   7.200000\n",
       "3   164.448276         0.80    6.2   4.700000\n",
       "4    84.000000         0.79    6.0   4.600000\n",
       "5    80.000000         0.77    5.8   4.300000\n",
       "6    80.000000         0.81    5.9   4.300000\n",
       "7    76.000000         0.81    5.8   4.000000\n",
       "8   178.000000         0.92    7.1   7.691379\n",
       "9   172.000000         0.89    7.4   7.000000\n",
       "10  166.000000         0.93    6.9   7.300000\n",
       "11  172.000000         0.92    7.1   7.600000\n",
       "12  154.000000         0.88    7.0   7.100000\n",
       "13  164.000000         0.70    7.3   7.700000\n",
       "14  152.000000         0.69    7.6   7.300000\n",
       "15  156.000000         0.69    7.7   7.100000\n",
       "16  156.000000         0.67    7.6   7.500000\n",
       "17  168.000000         0.73    7.5   7.600000\n",
       "18  162.000000         0.83    7.5   7.100000\n",
       "19  162.000000         0.85    7.4   7.200000\n",
       "20  160.000000         0.86    7.5   7.500000\n",
       "21  156.000000         0.84    7.4   7.400000\n",
       "22  140.000000         0.87    7.3   7.100000\n",
       "23  170.000000         0.88    7.6   7.900000\n",
       "24  342.000000         0.75    9.0   9.400000\n",
       "25  356.000000         0.75    9.2   9.200000\n",
       "26  362.000000         0.74    9.6   9.200000\n",
       "27  204.000000         0.77    7.5   9.200000\n",
       "28  140.000000         0.72    6.7   7.100000\n",
       "29  160.000000         0.81    7.0   7.400000\n",
       "30  158.000000         0.79    7.1   7.500000\n",
       "31  210.000000         0.82    7.8   8.000000\n",
       "32  164.000000         0.80    7.2   7.000000\n",
       "33  190.000000         0.74    7.5   8.100000\n",
       "34  142.000000         0.75    7.6   7.800000\n",
       "35  150.000000         0.75    7.1   7.900000\n",
       "36  160.000000         0.76    7.1   7.600000\n",
       "37  154.000000         0.79    7.3   7.300000\n",
       "38  158.000000         0.77    7.2   7.800000\n",
       "39  144.000000         0.75    6.8   7.400000\n",
       "40  154.000000         0.78    7.1   7.500000\n",
       "41  180.000000         0.79    7.6   8.200000\n",
       "42  154.000000         0.82    7.2   7.200000\n",
       "43  194.000000         0.70    7.2  10.300000\n",
       "44  200.000000         0.72    7.3  10.500000\n",
       "45  186.000000         0.72    7.2   9.200000\n",
       "46  216.000000         0.71    7.3  10.200000\n",
       "47  196.000000         0.72    7.3   9.700000\n",
       "48  174.000000         0.72    7.3  10.100000\n",
       "49  132.000000         0.73    5.8   8.700000\n",
       "50  130.000000         0.71    6.0   8.200000\n",
       "51  116.000000         0.72    6.0   7.500000\n",
       "52  118.000000         0.72    5.9   8.000000\n",
       "53  120.000000         0.74    6.0   8.400000\n",
       "54  116.000000         0.71    6.1   8.500000\n",
       "55  116.000000         0.72    6.3   7.700000\n",
       "56  116.000000         0.73    5.9   8.100000\n",
       "57  152.000000         0.72    6.5   8.500000\n",
       "58  118.000000         0.70    6.1   8.100000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['mass','color_score','width','height']].fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('fruit_data_with_colors.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['mass','height','width','color_score']]\n",
    "y = data['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fruit_name  fruit_subtype  mass  width  height  color_score\n",
       "fruit_label                                                             \n",
       "1                    19             19    19     19      19           19\n",
       "2                     5              5     5      5       5            5\n",
       "3                    19             19    19     19      19           19\n",
       "4                    16             16    16     16      16           16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('fruit_label').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for i in range(0,X_test.shape[0]):\n",
    "    if(y_test.values[i] == [4]):\n",
    "        tot += 1\n",
    "print(tot/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goncalves/anaconda/lib/python3.6/site-packages/sklearn/dummy.py:220: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  k in range(self.n_outputs_)).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.40      0.40         5\n",
      "          3       0.43      0.60      0.50         5\n",
      "          4       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       0.61      0.53      0.55        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_diabetes()['data']\n",
    "y = load_diabetes()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "svr = SVR().fit(X_train,y_train)\n",
    "knn = KNeighborsRegressor().fit(X_train,y_train)\n",
    "dummy = DummyRegressor().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40921945506792023\n",
      "0.0031010409629163016\n",
      "0.29566769691870376\n",
      "-0.013581960045605745\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_test,y_test))\n",
    "print(svr.score(X_test,y_test))\n",
    "print(knn.score(X_test,y_test))\n",
    "print(dummy.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.54009072013427"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.mean_absolute_error(y_test,svr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84       127\n",
      "          1       0.82      0.88      0.85       123\n",
      "\n",
      "avg / total       0.85      0.84      0.84       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       126\n",
      "          1       0.83      0.85      0.84       124\n",
      "\n",
      "avg / total       0.84      0.84      0.84       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       119\n",
      "          1       0.89      0.83      0.86       131\n",
      "\n",
      "avg / total       0.86      0.86      0.86       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.84       117\n",
      "          1       0.88      0.83      0.85       133\n",
      "\n",
      "avg / total       0.85      0.85      0.85       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86       134\n",
      "          1       0.84      0.84      0.84       116\n",
      "\n",
      "avg / total       0.85      0.85      0.85       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.81      0.85       136\n",
      "          1       0.80      0.89      0.84       114\n",
      "\n",
      "avg / total       0.85      0.85      0.85       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.84      0.82       115\n",
      "          1       0.86      0.81      0.84       135\n",
      "\n",
      "avg / total       0.83      0.83      0.83       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.82      0.84       125\n",
      "          1       0.83      0.87      0.85       125\n",
      "\n",
      "avg / total       0.85      0.85      0.85       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83       117\n",
      "          1       0.85      0.83      0.84       133\n",
      "\n",
      "avg / total       0.84      0.84      0.84       250\n",
      "\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.83      0.84       119\n",
      "          1       0.85      0.85      0.85       131\n",
      "\n",
      "avg / total       0.84      0.84      0.84       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "X,y = make_classification(n_samples=1000,\n",
    "                   flip_y=0.2)\n",
    "param_grid = {'C':[1,1.5,2.0,5,10],\n",
    "             'gamma':['auto',1,2,5,10],\n",
    "             'kernel':['rbf']}\n",
    "gs = GridSearchCV(SVC(),\n",
    "                  param_grid=param_grid,\n",
    "                  verbose=1,\n",
    "                  cv=5)\n",
    "for i in range(0,10):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "    gs.fit(X_train,y_train)\n",
    "    preds = gs.best_estimator_.predict(X_test)\n",
    "    print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import pca\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('fruit_data_with_colors.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['mass','height','width','color_score']]\n",
    "y = data['fruit_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca.PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transf = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njCZ2pZTKMZrYlVIqx2hiV0qpHPP/Ab0UIQH/9cDYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1240b6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_transf[:,0],X_transf[:,1],c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = data[['mass','height','width','color_score','fruit_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>color_score</th>\n",
       "      <th>fruit_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609571</td>\n",
       "      <td>0.877687</td>\n",
       "      <td>-0.079794</td>\n",
       "      <td>0.032738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.609571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396848</td>\n",
       "      <td>-0.247047</td>\n",
       "      <td>0.508766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>0.877687</td>\n",
       "      <td>0.396848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076576</td>\n",
       "      <td>-0.298090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_score</th>\n",
       "      <td>-0.079794</td>\n",
       "      <td>-0.247047</td>\n",
       "      <td>-0.076576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.310521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit_label</th>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.508766</td>\n",
       "      <td>-0.298090</td>\n",
       "      <td>-0.310521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mass    height     width  color_score  fruit_label\n",
       "mass         1.000000  0.609571  0.877687    -0.079794     0.032738\n",
       "height       0.609571  1.000000  0.396848    -0.247047     0.508766\n",
       "width        0.877687  0.396848  1.000000    -0.076576    -0.298090\n",
       "color_score -0.079794 -0.247047 -0.076576     1.000000    -0.310521\n",
       "fruit_label  0.032738  0.508766 -0.298090    -0.310521     1.000000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "pc = pca.PCA(n_components=1)\n",
    "Xtr = pc.fit_transform(X_train)\n",
    "Xte = pc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.fit(np.array(X_train['height']).reshape(-1,1),y_train)\n",
    "lr2.fit(Xtr,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(lr1.score(np.array(X_test['height']).reshape(-1,1),y_test))\n",
    "print(lr2.score(Xte,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20421038, 0.2621441 , 0.21546741, 0.3181781 ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2)\n",
    "km.fit(X)\n",
    "db = dbscan(X,eps=0.5,min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         16,  17,  19,  20,  21,  23,  25,  26,  27,  28,  29,  30,  31,\n",
       "         34,  35,  36,  37,  38,  39,  40,  42,  43,  45,  46,  47,  48,\n",
       "         49,  51,  54,  55,  61,  63,  67,  69,  71,  74,  78,  82,  83,\n",
       "         86,  88,  89,  91,  92,  94,  95,  96,  97,  99, 104, 111, 112,\n",
       "        116, 123, 126, 127, 138, 140, 147]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        -1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,  1,  1, -1, -1,\n",
       "        -1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,\n",
       "        -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.predict(X)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=[10,10],solver='lbfgs',\n",
    "                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[10, 10], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9370629370629371"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
